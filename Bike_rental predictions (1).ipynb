{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as sp\n",
    "% %matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>instant</th>\n",
       "      <th>dteday</th>\n",
       "      <th>season</th>\n",
       "      <th>yr</th>\n",
       "      <th>mnth</th>\n",
       "      <th>hr</th>\n",
       "      <th>holiday</th>\n",
       "      <th>weekday</th>\n",
       "      <th>workingday</th>\n",
       "      <th>weathersit</th>\n",
       "      <th>temp</th>\n",
       "      <th>atemp</th>\n",
       "      <th>hum</th>\n",
       "      <th>windspeed</th>\n",
       "      <th>casual</th>\n",
       "      <th>registered</th>\n",
       "      <th>cnt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.2879</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.2727</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.2727</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>27</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.2879</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.2879</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   instant     dteday  season  yr  mnth  hr  holiday  weekday  workingday  \\\n",
       "0        1 2011-01-01       1   0     1   0        0        6           0   \n",
       "1        2 2011-01-01       1   0     1   1        0        6           0   \n",
       "2        3 2011-01-01       1   0     1   2        0        6           0   \n",
       "3        4 2011-01-01       1   0     1   3        0        6           0   \n",
       "4        5 2011-01-01       1   0     1   4        0        6           0   \n",
       "\n",
       "   weathersit  temp   atemp   hum  windspeed  casual  registered  cnt  \n",
       "0           1  0.24  0.2879  0.81        0.0       3          13   16  \n",
       "1           1  0.22  0.2727  0.80        0.0       8          32   40  \n",
       "2           1  0.22  0.2727  0.80        0.0       5          27   32  \n",
       "3           1  0.24  0.2879  0.75        0.0       3          10   13  \n",
       "4           1  0.24  0.2879  0.75        0.0       0           1    1  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bike_rentals = pd.read_csv(\"bike_rental_hour.csv\",parse_dates=[1])\n",
    "bike_rentals.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x279cd0c5208>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAEACAYAAABYq7oeAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nuvx/Pj6vf/N1u9cAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x279cd0e2978>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "bike_rentals.cnt.hist(bins=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the distibution of daily bike rentals is skewed to the right signifiing large outliner on the higher end of the scale.mean is 189 trimmed mean(10%) is 162 and median is 142."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "instant       0.278379\n",
       "season        0.178056\n",
       "yr            0.250495\n",
       "mnth          0.120638\n",
       "hr            0.394071\n",
       "holiday      -0.030927\n",
       "weekday       0.026900\n",
       "workingday    0.030284\n",
       "weathersit   -0.142426\n",
       "temp          0.404772\n",
       "atemp         0.400929\n",
       "hum          -0.322911\n",
       "windspeed     0.093234\n",
       "casual        0.694564\n",
       "registered    0.972151\n",
       "cnt           1.000000\n",
       "Name: cnt, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bike_rentals.corr()['cnt']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "hour rented(hr) seems to have a moderate corrleation,\n",
    "A machine will treat each hour differently, and not understand that certain hours are related. We can introduce some order into this by creating a new column with labels for morning, afternoon, evening, and night. This will bundle up similar times together, and enable the model to make better decisions.\n",
    "we will have to assingn a numeric number for this categorical variable in order for it to run on the machine learning algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def assign_label(hour):\n",
    "    if hour >=0 and hour < 6:\n",
    "        return 4\n",
    "    elif hour >=6 and hour < 12:\n",
    "        return 1\n",
    "    elif hour >= 12 and hour < 18:\n",
    "        return 2\n",
    "    elif hour >= 18 and hour <=24:\n",
    "        return 3\n",
    "\n",
    "bike_rentals[\"time_label\"] = bike_rentals[\"hr\"].apply(assign_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before you can start applying machine learning algorithms, you'll need to split the data into training and testing sets. This will enable you to train an algorithm using the training set and evaluate its accuracy on the testing set. If you train an algorithm on the training data, and evaluate its performance on the same data, you can get an unrealistically low error value, due to overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Error metric\n",
    "The mean squared error metric makes the most sense to evaluate our error. MSE works on continuous numeric data, which fits our data quite well.\n",
    "\n",
    "we will ignore the casual and registered columns because cnt is derived from these columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = bike_rentals.sample(frac=.8)\n",
    "test = bike_rentals.loc[~bike_rentals.index.isin(train.index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "predictors = list(train.columns)\n",
    "predictors.remove(\"cnt\")\n",
    "predictors.remove(\"casual\")\n",
    "predictors.remove(\"registered\")\n",
    "predictors.remove(\"dteday\")\n",
    "\n",
    "reg = LinearRegression()\n",
    "\n",
    "reg.fit(train[predictors], train[\"cnt\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17124.315499919772"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = reg.predict(test[predictors])\n",
    "\n",
    "np.mean((predictions - test[\"cnt\"]) ** 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Error\n",
    "The error is very high, which may be due to the fact that the data has a few extremely high rental counts, but otherwise mostly low counts. Larger errors are penalized more with MSE, which leads to a higher total error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Desicion trees\n",
    "Decision trees tend to predict outcomes much more reliably than linear regression. Because decision trees are a fairly complex model, they also tend to overfit, particularly when parameters such as maximum depth and minimum number of samples per leaf aren't tweaked. Decision trees are also prone to instability -- small changes in the input data can result in a very different output model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(criterion='mse', max_depth=None, max_features=None,\n",
       "           max_leaf_nodes=None, min_samples_leaf=5, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "           splitter='best')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "reg = DecisionTreeRegressor(min_samples_leaf=5)\n",
    "\n",
    "reg.fit(train[predictors], train[\"cnt\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2555.8362735108853"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#calculating MSE\n",
    "predictions = reg.predict(test[predictors])\n",
    "\n",
    "np.mean((predictions - test[\"cnt\"]) ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2688.917186101521"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg = DecisionTreeRegressor(min_samples_leaf=2)\n",
    "\n",
    "reg.fit(train[predictors], train[\"cnt\"])\n",
    "\n",
    "predictions = reg.predict(test[predictors])\n",
    "\n",
    "np.mean((predictions - test[\"cnt\"]) ** 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Decision tree error\n",
    "By taking the nonlinear predictors into account, the decision tree regressor appears to have much higher accuracy than linear regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1862.7810671154346"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "reg = RandomForestRegressor(min_samples_leaf=5)\n",
    "reg.fit(train[predictors], train[\"cnt\"])\n",
    "predictions = reg.predict(test[predictors])\n",
    "\n",
    "np.mean((predictions - test[\"cnt\"]) ** 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random forest error\n",
    "By removing some of the sources of overfitting, the random forest accuracy is improved over the decision tree accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
